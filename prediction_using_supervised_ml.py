# -*- coding: utf-8 -*-
"""Prediction using Supervised ML.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KAM0SDMKv0KI37auTCQS1kU8PcuUbz3l

# **Name of the intern:**  Souha Ghabri
# **Task #1:** Prediction using Supervised ML
## *Predicting the score of a student based on the number of study hours.*

### Let's start by importing the needed libraries
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

"""### Now let's load data in a DataFrame"""

df = pd.read_csv("http://bit.ly/w-data")
df.shape

df.head(25)

"""#### Here [0,24] gives us 25 element."""

df.info()

df.describe()

"""#Let's visualize the data """

sns.set_style('darkgrid')

plt.plot(df['Hours'],df['Scores'],'oc')
plt.xlabel('Num of Hours',fontsize = 20)
plt.ylabel('Scores',fontsize = 20)
plt.title('Num of Hours Vs. Scores',fontsize = 40)
plt.legend(['Scores']);

"""### Let's see a boxplot of our data"""

sns.boxplot(data=df[["Hours","Scores"]])

"""#### We notice here that there are no outliers in our data

### And also visualize a scatterplot of our data
"""

df.plot.scatter(x="Hours",y="Scores")
plt.title("Num of Hours vs. Scores")
plt.grid()
plt.show()

"""#### Which allows us to clearly see that there is a positive linear relationship between the number of studied hours and the scores.

### Let's prepare the data
"""

X = df.iloc[:, :-1].values
y = df.iloc[:, 1].values

"""### Let's split our Dataset into Train and Test"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, 
                                    test_size = 0.20, random_state = 0)

"""#### This is done by using 80% of our available data for training and 20% of the data for testing.

### In order to train the Algorithm
#### We will use the training data to train our Algorithm
"""

from sklearn.linear_model import LinearRegression  
regressor = LinearRegression()  
regressor.fit(X_train, y_train) 

print("The training is complete.")

line = regressor.coef_*X+regressor.intercept_

df.plot.scatter(x="Hours",y="Scores")
plt.plot(X, line);
plt.grid()
plt.show()

"""### Now let's make some Predictions"""

# Here we are predicting the scores 
y_pred = regressor.predict(X_test)
print(y_pred)

"""### Let's compare the actual Score to the predicted Score"""

df_compare = pd.DataFrame({"Actual Score":y_test,"Predicted Score":y_pred})
df_compare

"""### Here we are need to predict the score in the case which a student studies for 9.25 hours per day"""

my_hours = np.array([[9.25]])
my_pred = regressor.predict(my_hours)
print("No of Hours = {}".format(my_hours[0][0]))
print("Predicted Score = {}".format(my_pred[0]))

"""###Last step is evaluating the Model """

import sklearn.metrics as metrics

explained_variance=metrics.explained_variance_score(y_test, y_pred)
mean_absolute_error=metrics.mean_absolute_error(y_test, y_pred) 
mse=metrics.mean_squared_error(y_test, y_pred) 
mean_squared_log_error=metrics.mean_squared_log_error(y_test, y_pred)
median_absolute_error=metrics.median_absolute_error(y_test, y_pred)
r2=metrics.r2_score(y_test, y_pred)

print('Explained Variance: ', round(explained_variance,4))    
print('mean_squared_log_error: ', round(mean_squared_log_error,4))
print('r2: ', round(r2,4))
print('MAE: ', round(mean_absolute_error,4))
print('MSE: ', round(mse,4))
print('RMSE: ', round(np.sqrt(mse),4))